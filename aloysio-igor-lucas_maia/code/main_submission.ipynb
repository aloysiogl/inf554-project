{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "gradient-boosting-submission.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "f_DD5TYRBKBu"
      },
      "source": [
        "# Basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Sklearn tools\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# XGBoost's gradient boosting regressor\n",
        "import xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "YWPwf6phBKBx"
      },
      "source": [
        "# Reading competition data csv's\n",
        "dtypes = { 'id': int, 'timestamp': int, 'user_verified': bool, 'user_statuses_count': int, 'user_followers_count': int, \n",
        "          'user_friends_count': int, 'user_mentions': str, 'urls': str, 'hashtags': str, 'text': str }\n",
        "train_df = pd.read_csv('data/train.csv')\n",
        "eval_df = pd.read_csv('data/evaluation.csv')\n",
        "\n",
        "# Create numpy array of data\n",
        "train_y = np.array(train_df['retweet_count'])\n",
        "train_features = np.array(train_df[['user_followers_count', 'user_statuses_count', 'user_friends_count', 'user_verified']]).astype(np.float32)\n",
        "eval_features = np.array(eval_df[['user_followers_count', 'user_statuses_count', 'user_friends_count', 'user_verified']]).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9TG0Tbv4BKBy"
      },
      "source": [
        "# Load embeddings\n",
        "with open('data/train.pkl', 'rb') as f:\n",
        "    train_tweets = pickle.load(f).numpy()\n",
        "with open('data/evaluation.pkl', 'rb') as f:\n",
        "    eval_tweets = pickle.load(f).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vkm7UdLmBKBz"
      },
      "source": [
        "# PCA of tweets embeddings\n",
        "pca = PCA(2)\n",
        "pca.fit(np.concatenate([train_tweets, eval_tweets]))\n",
        "train_tweets = pca.transform(train_tweets)\n",
        "eval_tweets = pca.transform(eval_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8hkeR0oUBKBz"
      },
      "source": [
        "# Combine numerical and textual features\n",
        "train_x = pd.DataFrame(np.concatenate([train_features, train_tweets], axis=1))\n",
        "eval_x = pd.DataFrame(np.concatenate([eval_features, eval_tweets], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cWoQVuhVBKB0"
      },
      "source": [
        "def train_predict(train_x, train_y, test_x):\n",
        "    # Parameters tuned in grid cross-validation\n",
        "    n1, n2, alpha1, alpha2 = 40, 10, 0.4, 0.8\n",
        "    n_estimators, learning_rate, max_depth = 200, 0.08, 10\n",
        "\n",
        "    def filter_neighbors(neighbors_idx, neighbors_dist, kind):\n",
        "        \"\"\"\n",
        "        Filters neighbors based on user_verified, by lowering the distance to those neighbors which have \n",
        "        user_verified equal to the element.\n",
        "        @param neighbors_idx Index of the 'n1' neighbors for each element.\n",
        "        @param neighbors_dist Distance of the 'n1' neighbors for each element.\n",
        "        @param kind 'train' or 'test'\n",
        "        @return new_neighbors_idx Index of the 'n2+1' neighbors for each element.\n",
        "        \"\"\"\n",
        "        is_verified_train = train_x.iloc[:, 3]\n",
        "        is_verified_test = test_x.iloc[:, 3]\n",
        "        \n",
        "        new_neighbors_idx = np.zeros((len(neighbors_idx), n2+1), dtype=int)\n",
        "        for i in range(len(neighbors_idx)):\n",
        "            # Calculate vector with user_verified for each neighbor\n",
        "            neighbors_verified = is_verified_train.iloc[neighbors_idx[i]].astype(int)\n",
        "\n",
        "            # Lowers the distance by factors alpha1 or alpha2\n",
        "            if (kind == 'train' and is_verified_train.iloc[i]) or (kind == 'test' and is_verified_test.iloc[i]):\n",
        "                neighbors_dist[i, neighbors_verified] *= alpha1\n",
        "            else:\n",
        "                neighbors_dist[i, neighbors_verified] *= alpha2\n",
        "\n",
        "            # Sort neighbors with new distances\n",
        "            idx = np.argsort(neighbors_dist[i])[:n2+1].astype(int)\n",
        "\n",
        "            # Filter neighbors\n",
        "            new_neighbors_idx[i] = neighbors_idx[i, idx]\n",
        "        \n",
        "        return new_neighbors_idx\n",
        "\n",
        "    # First KNN, of n2 neighbors with 3 features: user_followers_count, user_friends_count and user_statuses_count\n",
        "    nn = NearestNeighbors(n_neighbors=n1)\n",
        "    nn.fit(train_x.iloc[:, :3], train_y)\n",
        "\n",
        "    # Calculate neighbors for training set. This will be used to train the XGBRegressor\n",
        "    dist, train_neighbors_idx = nn.kneighbors(train_x.iloc[:, :3])\n",
        "\n",
        "    # Filter neighbors based on user_verified value, selecting only n2+1 neighbors\n",
        "    train_neighbors_idx = filter_neighbors(train_neighbors_idx, dist, 'train')\n",
        "\n",
        "    # Sort neighbors based on retweet_count, filtering itself\n",
        "    train_neighbors_idx = np.array([i[np.argsort(train_y[i])] for i in train_neighbors_idx[:, 1:]])\n",
        "\n",
        "    # Calculate neighbors for testing set\n",
        "    dist, test_neighbors_idx = nn.kneighbors(test_x.iloc[:, :3])\n",
        "    test_neighbors_idx = filter_neighbors(test_neighbors_idx, dist, 'test')\n",
        "\n",
        "    # Sort neighbors based on retweet count, remove furthest one to keep only n2 neighbors\n",
        "    test_neighbors_idx = np.array([i[np.argsort(train_y[i])] for i in test_neighbors_idx[:, :-1]])\n",
        "\n",
        "    # Calculate prediction values for XBGRegressor, which are the index of the best neighbor of each element\n",
        "    train_best_neighbors_idx = []\n",
        "    for i in range(len(train_y)):\n",
        "        diff = abs(train_y[i] - train_y[train_neighbors_idx[i]])\n",
        "        train_best_neighbors_idx.append(np.argmin(diff))\n",
        "    train_best_neighbors_idx = np.array(train_best_neighbors_idx)\n",
        "\n",
        "    # Train regressor\n",
        "    xgb = xgboost.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, tree_method='gpu_hist', objective='reg:squarederror')\n",
        "    xgb.fit(train_x, train_best_neighbors_idx)\n",
        "    pred = xgb.predict(test_x)\n",
        "\n",
        "    # Truncate result (is better than rounding)\n",
        "    pred = pred.astype(int)\n",
        "\n",
        "    # Convert back to retweet_count\n",
        "    pred = np.array([train_y[test_neighbors_idx[i, np.clip(pred[i], 0, n2-1)]] for i in range(len(test_x))])\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXq4E0uPBTGb"
      },
      "source": [
        "pred = train_predict(train_x, train_y, eval_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LAufdTbDBKB2"
      },
      "source": [
        "submission = pd.DataFrame({ 'TweetID': eval_df['id'], 'NoRetweets': pred })\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}