{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# Base libraries\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","# Pytorch and tokenizers\n","import emoji\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import AutoModel, AutoTokenizer\n","\n","# Pretty progress bar\n","tqdm.pandas()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Load train dataset\n","dtypes = { 'id': int, 'timestamp': int, 'user_verified': bool, 'user_statuses_count': int, 'user_followers_count': int, \n","          'user_friends_count': int, 'user_mentions': str, 'urls': str, 'hashtags': str, 'text': str }\n","train_df = pd.read_csv('data/train.csv')\n","train_df = train_df['text']"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"collapsed":true},"cell_type":"code","source":["# Loadbertweet and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-covid19-base-cased', normalization=True)\n","bertweet = AutoModel.from_pretrained('vinai/bertweet-covid19-base-cased')\n","bertweet.cuda()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Tokenize train tweets\n","train_tokenized = tokenizer(list(train_df), padding=True, return_tensors='pt', truncation=True, max_length=128)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Create dataloader to feed into model\n","train_dataset = TensorDataset(train_tokenized['input_ids'], train_tokenized['token_type_ids'], train_tokenized['attention_mask'])\n","train_dataloader = DataLoader(train_dataset, batch_size=2048)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_features = torch.tensor([])\n","\n","for batch in tqdm(train_dataloader):\n","    input_ids = batch[0].cuda()\n","    token_type_ids = batch[1].cuda()\n","    attention_mask = batch[2].cuda()\n","\n","    with torch.no_grad():\n","        # Get bert's front-propagation output\n","        fts = bertweet(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","        fts = fts[1].detach().cpu()\n","\n","    # Concatenate batch results\n","    train_features = torch.cat([train_features, fts])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Save results in disk\n","with open('data/train.pkl', 'wb') as f:\n","    pickle.dump(train_features, f)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Load eval dataset\n","eval_df = pd.read_csv('data/evaluation.csv')\n","eval_df = train_df['text']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Tokenize eval tweets\n","eval_tokenized = tokenizer(list(eval_df), padding=True, return_tensors='pt', truncation=True, max_length=128)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Create eval dataloader\n","eval_dataset = TensorDataset(eval_tokenized['input_ids'], eval_tokenized['token_type_ids'], eval_tokenized['attention_mask'])\n","eval_dataloader = DataLoader(eval_dataset, batch_size=2048)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["eval_features = torch.tensor([])\n","\n","for batch in tqdm(eval_dataloader):\n","    input_ids = batch[0].cuda()\n","    token_type_ids = batch[1].cuda()\n","    attention_mask = batch[2].cuda()\n","\n","    with torch.no_grad():\n","        # Get bert's front-propagation output\n","        fts = bertweet(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","        fts = fts[1].detach().cpu()\n","\n","    # Concatenate batch results\n","    eval_features = torch.cat([eval_features, fts])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Save results in disk\n","with open('data/evaluation.pkl', 'wb') as f:\n","    pickle.dump(eval_features, f)"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}